import re
import pandas as pd
import matplotlib.pyplot as plt
import argparse
import os
from datetime import datetime
import numpy as np
from matplotlib.ticker import EngFormatter, MultipleLocator

def analyze_log(log_file, max_lines=None, time_window=0.1, aggregate=False):
    """è§£æMsQuic BBRæ—¥å¿—æ ¼å¼ï¼Œå¯é€‰æ‹©æ˜¯å¦æŒ‰æ—¶é—´çª—å£èšåˆæ•°æ®"""
    bbr_data = []
    packet_lost_events = []  # å­˜å‚¨ä¸¢åŒ…äº‹ä»¶
    
    # æ·»åŠ è®¡æ•°å™¨æ¥è·Ÿè¸ªå„ç§äº‹ä»¶ç±»å‹
    sent_count = 0
    acked_count = 0
    lost_count = 0
    other_count = 0
    
    # è·Ÿè¸ªä¸Šä¸€ä¸ªACKäº‹ä»¶çš„TotalLostå€¼
    last_ack_total_lost = 0
    
    line_count = 0
    print(f"Analyzing log file: {log_file}")
    
    with open(log_file, 'r') as f:
        for line in f:
            line_count += 1
            if max_lines and line_count > max_lines:
                break
                
            if line_count % 1000 == 0:
                print(f"Processed {line_count} lines...")
            
            # å¤„ç†BBR-PKT-SENTã€BBR-PKT-ACKEDå’ŒBBR-PKT-LOSTæ ¼å¼çš„æ—¥å¿—
            is_bbr_pkt_sent = "[BBR-PKT-SENT]" in line
            is_bbr_pkt_acked = "[BBR-PKT-ACKED]" in line
            is_bbr_pkt_lost = "[BBR-PKT-LOST]" in line
            
            # æ›´æ–°äº‹ä»¶è®¡æ•°
            if is_bbr_pkt_sent:
                sent_count += 1
            elif is_bbr_pkt_acked:
                acked_count += 1
            elif is_bbr_pkt_lost:
                lost_count += 1
            else:
                other_count += 1
            
            try:
                # è§£ææ—¶é—´æˆ³
                time_match = re.search(r'T=([\d\.]+) s', line)
                if not time_match:
                    continue
                    
                time_sec = float(time_match.group(1))
                
                # æå–åŒ…å·å’Œå¤§å°
                pkt_match = re.search(r'PKT=(\d+)', line)
                size_match = re.search(r'Size=(\d+) B', line)
                packet_number = int(pkt_match.group(1)) if pkt_match else 0
                packet_size = int(size_match.group(1)) if size_match else 0
                
                # æå–TotalLost
                total_sent_match = re.search(r'TotalSent=(\d+)', line)
                total_lost_match = re.search(r'TotalLost=(\d+)', line)
                total_sent = int(total_sent_match.group(1)) if total_sent_match else 0
                total_lost = int(total_lost_match.group(1)) if total_lost_match else 0
                
                # æ›´æ–°ACKäº‹ä»¶çš„TotalLost
                if is_bbr_pkt_acked:
                    last_ack_total_lost = total_lost
                    continue
                
                if not (is_bbr_pkt_sent or is_bbr_pkt_lost):
                    continue
                    
                # æå–ä¼°è®¡å¸¦å®½
                estbw_match = re.search(r'EstBW=([\d\.]+) Mbps', line)
                estbw_mbps = float(estbw_match.group(1)) if estbw_match else 0
                
                # æå–Pacing Rate
                pacing_match = re.search(r'PacingRate=([\d\.]+) Mbps', line)
                pacing_rate_mbps = float(pacing_match.group(1)) if pacing_match else 0
                
                # æå–Delivery Rate
                delivery_match = re.search(r'DeliveryRate=([\d\.]+) Mbps', line)
                delivery_rate_mbps = float(delivery_match.group(1)) if delivery_match else 0
                
                # æå–RTT
                rtt_match = re.search(r'RTT=(\d+) us', line)
                rtt_us = int(rtt_match.group(1)) if rtt_match else 0
                
                # æå–MinRTT
                min_rtt_match = re.search(r'MinRTT=(\d+) us', line)
                min_rtt_us = int(min_rtt_match.group(1)) if min_rtt_match else 0
                
                # æå–CWND
                cwnd_match = re.search(r'CWND=(\d+) B', line)
                cwnd_bytes = int(cwnd_match.group(1)) if cwnd_match else 0
                
                # æå–InFlight
                inflight_match = re.search(r'InFlight=(\d+) B', line)
                inflight_bytes = int(inflight_match.group(1)) if inflight_match else 0
                
                # æå–Lossç‡å’Œä¸¢åŒ…æ•°
                loss_rate_match = re.search(r'Loss=([\d\.]+)%', line)
                loss_rate = float(loss_rate_match.group(1)) if loss_rate_match else 0.0
                
                # æå–BBR State
                state_match = re.search(r'State=(\w+)', line)
                bbr_state = state_match.group(1) if state_match else "Unknown"
                
                # æå–Send Delayå’ŒAck Delay
                send_delay_match = re.search(r'SendDelay=(\d+) us', line)
                ack_delay_match = re.search(r'AckDelay=(\d+) us', line)
                send_delay_us = int(send_delay_match.group(1)) if send_delay_match else 0
                ack_delay_us = int(ack_delay_match.group(1)) if ack_delay_match else 0
                
                # æå–PacingGainå’ŒCwndGain
                pacing_gain_match = re.search(r'PacingGain=([\d\.]+)x', line)
                cwnd_gain_match = re.search(r'CwndGain=([\d\.]+)x', line)
                pacing_gain = float(pacing_gain_match.group(1)) if pacing_gain_match else 0
                cwnd_gain = float(cwnd_gain_match.group(1)) if cwnd_gain_match else 0
                
                if is_bbr_pkt_sent:
                    # å¤„ç†æ‰€æœ‰SENTäº‹ä»¶ï¼Œä¸å†ä»…é™äºACKåçš„ç¬¬ä¸€ä¸ª
                    # åˆ›å»ºæ•°æ®ç‚¹
                    data_point = {
                        'time_sec': time_sec,
                        'packet_number': packet_number,
                        'packet_size': packet_size,
                        'send_mbps': 0,  # è¿™äº›å­—æ®µåœ¨æ–°æ—¥å¿—ä¸­æ²¡æœ‰ï¼Œè®¾ä¸º0
                        'recv_mbps': 0,
                        'btlbw_mbps': estbw_mbps,
                        'pacing_rate_mbps': pacing_rate_mbps,
                        'delivery_rate_mbps': delivery_rate_mbps,
                        'rtt_ms': rtt_us / 1000.0,  # è½¬æ¢ä¸ºæ¯«ç§’
                        'rtprop_ms': min_rtt_us / 1000.0,  # è½¬æ¢ä¸ºæ¯«ç§’
                        'cwnd_kb': cwnd_bytes / 1024.0,  # è½¬æ¢ä¸ºKB
                        'bytes_in_flight_kb': inflight_bytes / 1024.0,  # è½¬æ¢ä¸ºKB
                        'lost_packets': total_lost,
                        'loss_rate': loss_rate,  # ä¿å­˜ä¸¢åŒ…ç‡
                        'bbr_state': bbr_state,
                        'pacing_gain': pacing_gain,  # ä½¿ç”¨ä»æ—¥å¿—ä¸­æå–çš„å¢ç›Šå› å­
                        'cwnd_gain': cwnd_gain,
                        'send_delay_ms': send_delay_us / 1000.0,  # è½¬æ¢ä¸ºæ¯«ç§’
                        'ack_delay_ms': ack_delay_us / 1000.0,     # è½¬æ¢ä¸ºæ¯«ç§’
                        'raw_log': line.strip(),  # ä¿å­˜åŸå§‹æ—¥å¿—è¡Œ
                        'is_valid': True  # æ‰€æœ‰SENTäº‹ä»¶éƒ½æ ‡è®°ä¸ºæœ‰æ•ˆ
                    }
                    
                    # å°†æ•°æ®ç‚¹æ·»åŠ åˆ°åˆ—è¡¨
                    bbr_data.append(data_point)
                
                # å¦‚æœæ˜¯ä¸¢åŒ…äº‹ä»¶ï¼Œè®°å½•ä¸¢åŒ…ä¿¡æ¯
                if is_bbr_pkt_lost:
                    # è®¡ç®—è¿™æ¬¡ä¸¢åŒ…äº‹ä»¶çš„å®é™…ä¸¢åŒ…æ•°ï¼ˆç›¸å¯¹äºä¸Šä¸€ä¸ªACKäº‹ä»¶ï¼‰
                    actual_lost_packets = total_lost - last_ack_total_lost
                    if actual_lost_packets < 0:
                        actual_lost_packets = 1  # é˜²æ­¢å‡ºç°è´Ÿæ•°ï¼Œè‡³å°‘ä¸¢äº†1ä¸ªåŒ…
                        
                    persistent_congestion = "YES" in line if "PersistentCongestion=YES" in line else False
                    packet_lost_events.append({
                        'time_sec': time_sec,
                        'packet_number': packet_number,
                        'packet_size': packet_size,
                        'lost_packets': actual_lost_packets,  # è¿™æ¬¡äº‹ä»¶çš„å®é™…ä¸¢åŒ…æ•°
                        'total_lost': total_lost,             # ä¿ç•™ç´¯è®¡ä¸¢åŒ…æ•°ç”¨äºå‚è€ƒ
                        'total_sent': total_sent,
                        'loss_rate': loss_rate,
                        'persistent_congestion': persistent_congestion,
                        'pacing_gain': pacing_gain,           # æ·»åŠ pacing_gain
                        'cwnd_gain': cwnd_gain,               # æ·»åŠ cwnd_gain
                        'raw_log': line.strip()  # ä¿å­˜åŸå§‹æ—¥å¿—è¡Œ
                    })
                
            except Exception as e:
                if line_count < 20:  # åªå¯¹å‰20è¡Œæ‰“å°é”™è¯¯
                    print(f"Error parsing line {line_count}: {str(e)}")
                    print(f"Line content: {line[:100]}...")
    
    # æ‰“å°è¯¦ç»†çš„äº‹ä»¶ç»Ÿè®¡
    print(f"\n=== Detailed Event Statistics ===")
    print(f"Total lines: {line_count}")
    print(f"SENT events: {sent_count} ({sent_count/line_count*100:.1f}%)")
    print(f"ACKED events: {acked_count} ({acked_count/line_count*100:.1f}%)")
    print(f"LOST events: {lost_count} ({lost_count/line_count*100:.1f}%)")
    print(f"Other lines: {other_count} ({other_count/line_count*100:.1f}%)")
    print(f"Total sampled SENT events: {len(bbr_data)} ({len(bbr_data)/sent_count*100:.1f}% of SENT)")
    print(f"=== End of Event Statistics ===\n")
    
    print(f"Finished processing {line_count} lines. Found {len(bbr_data)} SENT events and {len(packet_lost_events)} packet loss events.")
    
    if not bbr_data:
        return None, None, None
    
    # åˆ›å»ºDataFrame
    bbr_df = pd.DataFrame(bbr_data)
    
    # æŒ‰æ—¶é—´æ’åº
    bbr_df = bbr_df.sort_values('time_sec').reset_index(drop=True)
    
    # å°†æ‰€æœ‰é‡‡æ ·ç‚¹çš„å…·ä½“æ•°å€¼è¾“å‡ºåˆ°TXTæ–‡ä»¶
    output_txt_file = os.path.splitext(log_file)[0] + "_sampling_points.txt"
    with open(output_txt_file, 'w') as f:
        f.write("=== BBR Sampling Points Detailed Data ===\n")
        f.write(f"Total sampling points: {len(bbr_df)}\n")
        f.write(f"Data sampling method: All SENT events\n\n")
        
        f.write("No.,Time(s),PacketNo,Size(B),EstBW(Mbps),PacingRate(Mbps),DeliveryRate(Mbps),RTT(ms),MinRTT(ms),CWND(KB),BytesInFlight(KB),LostPackets,LossRate(%),BBRState,SendDelay(ms),AckDelay(ms),PacingGain,CwndGain\n")
        
        for i, row in bbr_df.iterrows():
            f.write(f"{i+1},{row['time_sec']:.3f},{row['packet_number']},{row['packet_size']:.0f},{row['btlbw_mbps']:.2f},{row['pacing_rate_mbps']:.2f},{row['delivery_rate_mbps']:.2f},{row['rtt_ms']:.2f},{row['rtprop_ms']:.2f},{row['cwnd_kb']:.2f},{row['bytes_in_flight_kb']:.2f},{row['lost_packets']},{row['loss_rate']:.2f},{row['bbr_state']},{row['send_delay_ms']:.2f},{row['ack_delay_ms']:.2f},{row['pacing_gain']:.2f},{row['cwnd_gain']:.2f}\n")
        
        f.write("\n=== Raw Log Lines ===\n")
        for i, row in bbr_df.iterrows():
            if 'raw_log' in row:
                f.write(f"{i+1}: {row['raw_log']}\n")
    
    print(f"Sampling points detailed data saved to: {output_txt_file}")
    
    if aggregate:
        # æ•°æ®èšåˆå¤„ç†ï¼šæŒ‰æ—¶é—´çª—å£åˆ†ç»„
        print(f"Aggregating data with time window: {time_window}s...")
        
        # åˆ›å»ºæ—¶é—´çª—å£æ ‡è¯†ç¬¦
        bbr_df['time_window'] = (bbr_df['time_sec'] / time_window).round() * time_window
        
        # æŒ‰æ—¶é—´çª—å£èšåˆæ•°æ® - ä½¿ç”¨å¹³å‡å€¼è€Œä¸æ˜¯ç´¯åŠ 
        agg_functions = {
            'time_sec': 'first',  # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ—¶é—´æˆ³ä½œä¸ºä»£è¡¨
            'packet_number': 'max',
            'packet_size': 'mean',
            'send_mbps': 'mean',
            'recv_mbps': 'mean', 
            'btlbw_mbps': 'mean',  # ä½¿ç”¨å¹³å‡å€¼
            'pacing_rate_mbps': 'mean',  # ä½¿ç”¨å¹³å‡å€¼
            'delivery_rate_mbps': 'mean',  # ä½¿ç”¨å¹³å‡å€¼
            'rtt_ms': 'mean',
            'rtprop_ms': 'min',  # MinRTTä½¿ç”¨æœ€å°å€¼
            'cwnd_kb': 'mean',
            'bytes_in_flight_kb': 'mean',
            'lost_packets': 'max',  # ä¸¢åŒ…æ•°ä½¿ç”¨æœ€å¤§å€¼ï¼ˆç´¯ç§¯ï¼‰
            'loss_rate': 'mean',    # ä½¿ç”¨å¹³å‡ä¸¢åŒ…ç‡
            'bbr_state': 'last',    # BBRçŠ¶æ€ä½¿ç”¨æœ€åä¸€ä¸ª
            'pacing_gain': 'mean',
            'cwnd_gain': 'mean',
            'send_delay_ms': 'mean',
            'ack_delay_ms': 'mean',
            'is_valid': 'all'       # ä¿ç•™æœ‰æ•ˆæ€§æ ‡è®°
        }
        
        # æ‰§è¡Œèšåˆ
        bbr_df_final = bbr_df.groupby('time_window').agg(agg_functions).reset_index()
        
        # æŒ‰æ—¶é—´æ’åº
        bbr_df_final = bbr_df_final.sort_values('time_sec').reset_index(drop=True)
        
        print(f"Data aggregated: {len(bbr_data)} -> {len(bbr_df_final)} data points")
    else:
        # ä¸èšåˆï¼Œä½¿ç”¨æ‰€æœ‰åŸå§‹æ•°æ®ç‚¹
        print("Keeping all original data points (no aggregation)...")
        bbr_df_final = bbr_df
        print(f"Total data points: {len(bbr_df_final)}")
    
    # åŸºæœ¬çš„å¼‚å¸¸å€¼è¿‡æ»¤
    print("Filtering anomalous values...")
    
    # è¿‡æ»¤æ‰æ— æ•ˆçš„RTTå€¼
    bbr_df_final.loc[bbr_df_final['rtt_ms'] == 0, 'rtt_ms'] = np.nan
    bbr_df_final.loc[bbr_df_final['rtprop_ms'] == 0, 'rtprop_ms'] = np.nan
    
    # è¿‡æ»¤æ‰æ˜æ˜¾å¼‚å¸¸çš„RTTå€¼ï¼ˆè¶…è¿‡1000msï¼‰
    bbr_df_final.loc[bbr_df_final['rtt_ms'] > 1000, 'rtt_ms'] = np.nan
    bbr_df_final.loc[bbr_df_final['rtprop_ms'] > 1000, 'rtprop_ms'] = np.nan
    
    # è¿‡æ»¤æ‰æ˜æ˜¾å¼‚å¸¸çš„å¸¦å®½å€¼ï¼ˆè¶…è¿‡2000 Mbpsï¼‰
    for col in ['btlbw_mbps', 'pacing_rate_mbps', 'delivery_rate_mbps']:
        if col in bbr_df_final.columns:
            bbr_df_final.loc[bbr_df_final[col] > 2000, col] = np.nan
    
    aggregation_status = "aggregated" if aggregate else "original"
    print(f"Final {aggregation_status} dataset: {len(bbr_df_final)} data points")
    
    # åˆ›å»ºä¸¢åŒ…äº‹ä»¶DataFrame
    packet_lost_df = None
    if packet_lost_events:
        packet_lost_df = pd.DataFrame(packet_lost_events)
        print(f"Found {len(packet_lost_df)} packet loss events")
    
    return bbr_df_final, None, packet_lost_df

def plot_four_charts(bbr_df, delivery_rate_df, retransmission_df, output_file, aggregated=False, rtt_style='scatter'):
    """ç»˜åˆ¶BBRåˆ†æå›¾è¡¨ - åŒ…å«å»¶è¿Ÿåˆ†æå’Œä¸¢åŒ…åˆ†æçš„å®Œæ•´å›¾è¡¨é›†åˆ"""
    if bbr_df is None:
        print("No BBR data to plot.")
        return
    
    # å¯¹äºéèšåˆçš„å¤§æ•°æ®é›†ï¼Œè¿›è¡Œé‡‡æ ·ä»¥æé«˜æ€§èƒ½
    original_length = len(bbr_df)
    # ä¸å†å¯¹å¤§æ•°æ®é›†è¿›è¡Œé‡‡æ ·ï¼Œå§‹ç»ˆä½¿ç”¨å…¨éƒ¨æ•°æ®ç‚¹
    bbr_df_plot = bbr_df
    print(f"Plotting all {len(bbr_df_plot)} data points")
    
    # æé«˜ç»˜å›¾æ€§èƒ½
    plt.rcParams['path.simplify'] = True
    plt.rcParams['path.simplify_threshold'] = 0.8
    plt.rcParams['agg.path.chunksize'] = 10000
    
    # è®¾ç½®é«˜è´¨é‡ç»˜å›¾æ ·å¼
    plt.style.use('seaborn-v0_8-whitegrid')
    
    # ç¡®å®šéœ€è¦çš„å­å›¾æ•°é‡
    num_subplots = 7  # åŸºç¡€å›¾è¡¨æ•°é‡ï¼ˆ6ä¸ªåŸæœ‰å›¾è¡¨ + 1ä¸ªåˆå¹¶çš„ä¸¢åŒ…å›¾è¡¨ï¼‰
    
    # åˆ›å»ºç«–ç›´æ’åˆ—çš„å­å›¾
    fig, axes = plt.subplots(num_subplots, 1, figsize=(14, num_subplots * 3.5), dpi=150)
    plt.subplots_adjust(hspace=0.35)  # å¢å¤§å­å›¾é—´è·ï¼Œä½¿æ ‡é¢˜å’Œåæ ‡è½´ä¸é‡å 
    
    # ç¡®ä¿axesæ˜¯æ•°ç»„å½¢å¼
    if num_subplots == 1:
        axes = [axes]
    
    # ä¸ºæ ‡é¢˜è®¾ç½®ç»Ÿä¸€æ ·å¼
    title_style = dict(fontsize=14, fontweight='bold', 
                     bbox=dict(facecolor='white', alpha=0.9, edgecolor='lightgray', boxstyle='round,pad=0.5'))
    
    current_ax_idx = 0
    
    # å›¾1: å¸¦å®½ä¼°è®¡å’Œä¼ è¾“é€Ÿç‡
    ax1 = axes[current_ax_idx]
    current_ax_idx += 1
    
    # åªä½¿ç”¨æœ‰æ•ˆçš„SENTç‚¹è¿›è¡Œç»Ÿè®¡è®¡ç®—
    valid_df = bbr_df[bbr_df['is_valid']] if 'is_valid' in bbr_df.columns else bbr_df
    
    # Filter valid values for statistics calculation
    btlbw_filtered = valid_df['btlbw_mbps'][valid_df['btlbw_mbps'] > 1] if 'btlbw_mbps' in valid_df.columns else pd.Series()
    pacing_rate_filtered = valid_df['pacing_rate_mbps'][valid_df['pacing_rate_mbps'] > 1] if 'pacing_rate_mbps' in valid_df.columns else pd.Series()
    delivery_rate_filtered = valid_df['delivery_rate_mbps'][valid_df['delivery_rate_mbps'] > 1] if 'delivery_rate_mbps' in valid_df.columns else pd.Series()
    
    # è®¡ç®—éé›¶å€¼çš„ç™¾åˆ†æ¯”
    btlbw_nonzero_pct = len(btlbw_filtered) / len(valid_df) * 100 if len(valid_df) > 0 and 'btlbw_mbps' in valid_df.columns else 0
    pacing_nonzero_pct = len(pacing_rate_filtered) / len(valid_df) * 100 if len(valid_df) > 0 and 'pacing_rate_mbps' in valid_df.columns else 0
    delivery_nonzero_pct = len(delivery_rate_filtered) / len(valid_df) * 100 if len(valid_df) > 0 and 'delivery_rate_mbps' in valid_df.columns else 0
    
    if 'btlbw_mbps' in bbr_df_plot.columns:
        ax1.plot(bbr_df_plot['time_sec'], bbr_df_plot['btlbw_mbps'], 'b-', linewidth=1.5, label='BtlBw (Mbps)')
    
    if 'pacing_rate_mbps' in bbr_df_plot.columns:
        ax1.plot(bbr_df_plot['time_sec'], bbr_df_plot['pacing_rate_mbps'], 'g--', linewidth=1.2, label='Pacing Rate (Mbps)')
        
        # æ·»åŠ å¹³å‡pacing rateçš„æ°´å¹³çº¿
        if len(pacing_rate_filtered) > 0:
            avg_pacing_rate = pacing_rate_filtered.mean()
            if not np.isnan(avg_pacing_rate):
                ax1.axhline(y=avg_pacing_rate, color='orange', linestyle=':', linewidth=2, 
                           alpha=0.8, label=f'Avg Pacing Rate ({avg_pacing_rate:.2f} Mbps)')
    
    if 'delivery_rate_mbps' in bbr_df_plot.columns:
        ax1.plot(bbr_df_plot['time_sec'], bbr_df_plot['delivery_rate_mbps'], 'r-', linewidth=1.2, label='Delivery Rate (Mbps)')
    
    # æ ‡è®°çŠ¶æ€è½¬æ¢
    if 'bbr_state' in bbr_df_plot.columns:
        state_changes = bbr_df_plot[bbr_df_plot['bbr_state'] != bbr_df_plot['bbr_state'].shift(1)]
        for _, row in state_changes.iterrows():
            ax1.axvline(x=row['time_sec'], color='red', linestyle='--', alpha=0.7)
            ax1.text(row['time_sec'], ax1.get_ylim()[1]*0.9, row['bbr_state'], 
                    rotation=90, ha='right', bbox=dict(facecolor='white', alpha=0.8))
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    stats_text = ""
    if 'btlbw_mbps' in valid_df.columns:
        avg_btlbw = btlbw_filtered.mean() if len(btlbw_filtered) > 0 else 0
        max_btlbw = btlbw_filtered.max() if len(btlbw_filtered) > 0 else 0
        min_btlbw = btlbw_filtered.min() if len(btlbw_filtered) > 0 else 0
        stats_text += f"Avg BtlBw: {avg_btlbw:.2f} Mbps\n"
        stats_text += f"Max BtlBw: {max_btlbw:.2f} Mbps\n"
        stats_text += f"Min BtlBw: {min_btlbw:.2f} Mbps\n\n"
    
    if 'pacing_rate_mbps' in valid_df.columns:
        avg_pacing_rate = pacing_rate_filtered.mean() if len(pacing_rate_filtered) > 0 else 0
        max_pacing_rate = pacing_rate_filtered.max() if len(pacing_rate_filtered) > 0 else 0
        min_pacing_rate = pacing_rate_filtered.min() if len(pacing_rate_filtered) > 0 else 0
        stats_text += f"Avg Pacing Rate: {avg_pacing_rate:.2f} Mbps\n"
        stats_text += f"Max Pacing Rate: {max_pacing_rate:.2f} Mbps\n"
        stats_text += f"Min Pacing Rate: {min_pacing_rate:.2f} Mbps\n\n"
    
    if 'delivery_rate_mbps' in valid_df.columns:
        avg_delivery = delivery_rate_filtered.mean() if len(delivery_rate_filtered) > 0 else 0
        max_delivery = delivery_rate_filtered.max() if len(delivery_rate_filtered) > 0 else 0
        min_delivery = delivery_rate_filtered.min() if len(delivery_rate_filtered) > 0 else 0
        stats_text += f"Avg Delivery: {avg_delivery:.2f} Mbps\n"
        stats_text += f"Max Delivery: {max_delivery:.2f} Mbps\n"
        stats_text += f"Min Delivery: {min_delivery:.2f} Mbps"
    
    if stats_text:
        ax1.text(0.02, 0.95, stats_text, transform=ax1.transAxes, 
                verticalalignment='top', bbox=dict(facecolor='white', alpha=0.7))
    
    ax1.set_ylabel('Bandwidth (Mbps)')
    ax1.set_title('Congestion Control Bandwidth Estimation and Delivery Rate', **title_style)
    ax1.grid(True, alpha=0.3)
    ax1.legend(loc='upper right')
    
    # å›¾2: RTTæµ‹é‡
    ax2 = axes[current_ax_idx]
    current_ax_idx += 1
    
    if 'rtprop_ms' in bbr_df_plot.columns:
        ax2.plot(bbr_df_plot['time_sec'], bbr_df_plot['rtprop_ms'], 'r-', linewidth=1.0, label='RTprop (ms)')
    
    if 'rtt_ms' in bbr_df_plot.columns:
        ax2.plot(bbr_df_plot['time_sec'], bbr_df_plot['rtt_ms'], 'purple', linewidth=2.0, label='Latest RTT (ms)')
    
    # æ·»åŠ RTTç»Ÿè®¡ä¿¡æ¯æ¡† - ä½¿ç”¨valid_dfæ›¿ä»£bbr_df
    stats_text = ""
    if 'rtprop_ms' in valid_df.columns and not valid_df['rtprop_ms'].isnull().all():
        avg_rtprop = valid_df['rtprop_ms'].mean()
        median_rtprop = valid_df['rtprop_ms'].median()
        max_rtprop = valid_df['rtprop_ms'].max()
        min_rtprop = valid_df['rtprop_ms'].min()
        stats_text += f"RTprop (ms):\n  Avg: {avg_rtprop:.2f}\n  Median: {median_rtprop:.2f}\n  Max: {max_rtprop:.2f}\n  Min: {min_rtprop:.2f}\n\n"

    if 'rtt_ms' in valid_df.columns and not valid_df['rtt_ms'].isnull().all():
        avg_latest_rtt = valid_df['rtt_ms'].mean()
        median_latest_rtt = valid_df['rtt_ms'].median()
        max_latest_rtt = valid_df['rtt_ms'].max()
        min_latest_rtt = valid_df['rtt_ms'].min()
        stats_text += f"Latest RTT (ms):\n  Avg: {avg_latest_rtt:.2f}\n  Median: {median_latest_rtt:.2f}\n  Max: {max_latest_rtt:.2f}\n  Min: {min_latest_rtt:.2f}"

    if stats_text:
        ax2.text(0.02, 0.95, stats_text, transform=ax2.transAxes, 
                verticalalignment='top', bbox=dict(facecolor='white', alpha=0.7))
    
    ax2.set_ylabel('RTT (ms)')
    ax2.set_title('RTT Measurements', **title_style)
    ax2.grid(True, alpha=0.3)
    ax2.legend(loc='upper right')
    
    # å›¾3: BBRçŠ¶æ€æœº
    ax3 = axes[current_ax_idx]
    current_ax_idx += 1
    
    if 'bbr_state' in bbr_df_plot.columns:
        states = bbr_df_plot['bbr_state'].unique()
        state_map = {state: i for i, state in enumerate(states)}
        bbr_df_plot['state_num'] = bbr_df_plot['bbr_state'].map(state_map)
        
        ax3.plot(bbr_df_plot['time_sec'], bbr_df_plot['state_num'], 'purple', drawstyle='steps-post', linewidth=2, label='BBR State')
        ax3.set_yticks(range(len(states)))
        ax3.set_yticklabels(states)
        ax3.set_ylabel('BBR State')
        
        # æ·»åŠ RTpropåˆ°å³ä¾§Yè½´
        ax3b = ax3.twinx()
        if 'rtprop_ms' in bbr_df_plot.columns:
            ax3b.plot(bbr_df_plot['time_sec'], bbr_df_plot['rtprop_ms'], 'r-', linewidth=1.2, label='RTprop (ms)')
            ax3b.set_ylabel('RTprop (ms)', color='r')
            ax3b.tick_params(axis='y', labelcolor='r')
        
        # æ·»åŠ çŠ¶æ€è½¬æ¢æ ‡è®°
        state_changes = bbr_df_plot[bbr_df_plot['bbr_state'] != bbr_df_plot['bbr_state'].shift(1)]
        for _, row in state_changes.iterrows():
            time_str = f"{row['time_sec']:.1f}s"
            ax3.text(row['time_sec'], state_map[row['bbr_state']], 
                    f"{row['bbr_state']}\n{time_str}", 
                    ha='center', va='bottom', 
                    bbox=dict(facecolor='lightyellow', alpha=0.8))
        
        # åˆå¹¶ä¸¤ä¸ªå›¾ä¾‹
        lines3, labels3 = ax3.get_legend_handles_labels()
        lines3b, labels3b = ax3b.get_legend_handles_labels()
        ax3.legend(lines3 + lines3b, labels3 + labels3b, loc='upper right')
    
    ax3.set_title('Congestion Control State Machine and RTprop', **title_style)
    ax3.grid(True, alpha=0.3)
    
    # å›¾4: BBRå¢ç›Šå› å­ - ä¿®å¤å¢ç›Šå› å­ç»˜å›¾é—®é¢˜
    ax4 = axes[current_ax_idx]
    current_ax_idx += 1
    
    # å…ˆç»˜åˆ¶çŠ¶æ€å˜åŒ–èƒŒæ™¯
    if 'bbr_state' in bbr_df_plot.columns:
        state_colors = {'Startup': 'lightyellow', 'Drain': 'lightblue', 'ProbeBW': 'lightgreen', 'ProbeRTT': 'mistyrose'}
        current_state = None
        start_time = None
        
        for i, row in bbr_df_plot.iterrows():
            if current_state != row['bbr_state']:
                if current_state is not None and start_time is not None:
                    end_time = row['time_sec']
                    color = state_colors.get(current_state, 'white')
                    ax4.axvspan(start_time, end_time, alpha=0.2, color=color)
                    
                    # åœ¨åŒºåŸŸä¸­å¿ƒæ·»åŠ çŠ¶æ€æ ‡ç­¾
                    mid_time = (start_time + end_time) / 2
                    ax4.text(mid_time, 0.05, current_state, 
                            transform=ax4.get_xaxis_transform(),
                            ha='center', va='bottom', fontsize=8,
                            bbox=dict(boxstyle='round', fc='white', alpha=0.8))
                
                current_state = row['bbr_state']
                start_time = row['time_sec']
        
        # å¤„ç†æœ€åä¸€ä¸ªçŠ¶æ€
        if current_state is not None and start_time is not None:
            end_time = bbr_df_plot['time_sec'].max()
            color = state_colors.get(current_state, 'white')
            ax4.axvspan(start_time, end_time, alpha=0.2, color=color)
            
            mid_time = (start_time + end_time) / 2
            ax4.text(mid_time, 0.05, current_state, 
                    transform=ax4.get_xaxis_transform(),
                    ha='center', va='bottom', fontsize=8,
                    bbox=dict(boxstyle='round', fc='white', alpha=0.8))
    
    # ç»˜åˆ¶å¢ç›Šå› å­ - ä¿®å¤æ•°æ®é—®é¢˜
    gain_plotted = False
    if 'pacing_gain' in bbr_df_plot.columns:
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„pacing_gainæ•°æ®
        valid_pacing_mask = (~bbr_df_plot['pacing_gain'].isnull()) & (bbr_df_plot['pacing_gain'] > 0) & (bbr_df_plot['pacing_gain'] < 10)
        if valid_pacing_mask.any():
            ax4.plot(bbr_df_plot['time_sec'], bbr_df_plot['pacing_gain'], 'g-', linewidth=1.5, label='Pacing Gain')
            gain_plotted = True
            print(f"Found {valid_pacing_mask.sum()} valid pacing_gain values")
    
    if 'cwnd_gain' in bbr_df_plot.columns:
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„cwnd_gainæ•°æ®
        valid_cwnd_mask = (~bbr_df_plot['cwnd_gain'].isnull()) & (bbr_df_plot['cwnd_gain'] > 0) & (bbr_df_plot['cwnd_gain'] < 10)
        if valid_cwnd_mask.any():
            ax4.plot(bbr_df_plot['time_sec'], bbr_df_plot['cwnd_gain'], 'r--', linewidth=1.5, label='CWND Gain')
            gain_plotted = True
            print(f"Found {valid_cwnd_mask.sum()} valid cwnd_gain values")
    
    # å¦‚æœæ²¡æœ‰æœ‰æ•ˆçš„å¢ç›Šæ•°æ®ï¼Œæ˜¾ç¤ºæç¤ºä¿¡æ¯
    if not gain_plotted:
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        pacing_gain_info = "No pacing_gain column"
        cwnd_gain_info = "No cwnd_gain column"
        
        if 'pacing_gain' in bbr_df_plot.columns:
            pacing_gain_count = (~bbr_df_plot['pacing_gain'].isnull()).sum()
            pacing_gain_info = f"pacing_gain: {pacing_gain_count} non-null values"
            if pacing_gain_count > 0:
                sample_values = bbr_df_plot['pacing_gain'].dropna().head(5).tolist()
                pacing_gain_info += f", samples: {sample_values}"
        
        if 'cwnd_gain' in bbr_df_plot.columns:
            cwnd_gain_count = (~bbr_df_plot['cwnd_gain'].isnull()).sum()
            cwnd_gain_info = f"cwnd_gain: {cwnd_gain_count} non-null values"
            if cwnd_gain_count > 0:
                sample_values = bbr_df_plot['cwnd_gain'].dropna().head(5).tolist()
                cwnd_gain_info += f", samples: {sample_values}"
        
        ax4.text(0.5, 0.5, f'No valid gain factor data available\n{pacing_gain_info}\n{cwnd_gain_info}', 
                transform=ax4.transAxes, ha='center', va='center', fontsize=10,
                bbox=dict(facecolor='white', alpha=0.8))
    
    # ä¸ºçŠ¶æ€è½¬æ¢æ·»åŠ å‚ç›´çº¿å’Œæ—¶é—´æ ‡ç­¾
    if 'bbr_state' in bbr_df_plot.columns:
        state_changes = bbr_df_plot[bbr_df_plot['bbr_state'] != bbr_df_plot['bbr_state'].shift(1)]
        for _, row in state_changes.iterrows():
            ax4.axvline(x=row['time_sec'], color='darkgoldenrod', linestyle='--', alpha=0.6, linewidth=1.0)
            time_str = f"{row['time_sec']:.1f}s"
            ax4.text(row['time_sec'], -0.05, time_str, 
                    transform=ax4.get_xaxis_transform(),
                    ha='center', va='top', fontsize=8,
                    bbox=dict(boxstyle='round', fc='white', ec='black', alpha=0.9, pad=0.4))
    
    # è®¾ç½®yè½´çš„åˆç†èŒƒå›´
    if gain_plotted:
        ax4.set_ylim(0, 4)  # BBRå¢ç›Šå› å­é€šå¸¸åœ¨0-4ä¹‹é—´
    
    ax4.set_ylabel('Gain Factor')
    if gain_plotted:
        ax4.legend(loc='upper right')
    ax4.grid(True, alpha=0.3)
    ax4.set_title('BBR State Transitions and Gain Factors', **title_style)
    
    # å›¾5: æ‹¥å¡çª—å£ - ç§»é™¤åˆ©ç”¨ç‡é»„çº¿ï¼Œé¿å…é®æŒ¡ç»Ÿè®¡ä¿¡æ¯
    ax5 = axes[current_ax_idx]
    current_ax_idx += 1
    
    if 'cwnd_kb' in bbr_df_plot.columns:
        ax5.plot(bbr_df_plot['time_sec'], bbr_df_plot['cwnd_kb'], 'b-', linewidth=2.0, label='CWND')
    if 'bytes_in_flight_kb' in bbr_df_plot.columns:
        ax5.plot(bbr_df_plot['time_sec'], bbr_df_plot['bytes_in_flight_kb'], 'r-', linewidth=1.5, label='Bytes in Flight')
    
    # æ·»åŠ çŠ¶æ€è½¬æ¢å‚ç›´çº¿
    if 'bbr_state' in bbr_df_plot.columns:
        state_changes = bbr_df_plot[bbr_df_plot['bbr_state'] != bbr_df_plot['bbr_state'].shift(1)]
        for _, row in state_changes.iterrows():
            ax5.axvline(x=row['time_sec'], color='darkgoldenrod', linestyle='--', alpha=0.6, linewidth=1.0)
            ax5.text(row['time_sec'], ax5.get_ylim()[1]*0.9, row['bbr_state'], 
                    rotation=90, ha='right', va='top', fontsize=8,
                    bbox=dict(facecolor='white', alpha=0.8))
    
    # æ·»åŠ CWNDç»Ÿè®¡ä¿¡æ¯ - æ”¾ç½®åœ¨å³ä¸Šè§’é¿å…é®æŒ¡ï¼Œä½¿ç”¨valid_df
    stats_text = ""
    if 'cwnd_kb' in valid_df.columns:
        median_cwnd = valid_df['cwnd_kb'].median()
        max_cwnd = valid_df['cwnd_kb'].max()
        min_cwnd = valid_df['cwnd_kb'].min()
        stats_text += f"CWND (KB):\n  Median: {median_cwnd:.2f}\n  Max: {max_cwnd:.2f}\n  Min: {min_cwnd:.2f}\n\n"
    if 'bytes_in_flight_kb' in valid_df.columns:
        avg_bif = valid_df['bytes_in_flight_kb'].mean()
        max_bif = valid_df['bytes_in_flight_kb'].max()
        min_bif = valid_df['bytes_in_flight_kb'].min()
        stats_text += f"Bytes in Flight (KB):\n  Avg: {avg_bif:.2f}\n  Max: {max_bif:.2f}\n  Min: {min_bif:.2f}\n"
        if 'cwnd_kb' in valid_df.columns:
            median_util = (valid_df['bytes_in_flight_kb'] / valid_df['cwnd_kb'] * 100).median()
            stats_text += f"Median Utilization: {median_util:.1f}%"
    
    if stats_text:
        ax5.text(0.98, 0.98, stats_text, transform=ax5.transAxes, 
                verticalalignment='top', horizontalalignment='right', bbox=dict(facecolor='white', alpha=0.7))
    
    ax5.set_ylabel('Size (KB)')
    ax5.set_title('Congestion Window', **title_style)
    ax5.grid(True, alpha=0.3)
    ax5.legend(loc='upper left')
    
    # å›¾6: Send Delay å’Œ Ack Delay - æ–°å¢çš„å»¶è¿Ÿåˆ†æå›¾
    ax6 = axes[current_ax_idx]
    current_ax_idx += 1
    
    delay_plotted = False
    if 'send_delay_ms' in bbr_df_plot.columns:
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„send_delayæ•°æ®
        valid_send_mask = (~bbr_df_plot['send_delay_ms'].isnull()) & (bbr_df_plot['send_delay_ms'] > 0) & (bbr_df_plot['send_delay_ms'] < 10000)
        if valid_send_mask.any():
            ax6.plot(bbr_df_plot['time_sec'], bbr_df_plot['send_delay_ms'], 'g-', linewidth=1.5, 
                    label='Send Delay (ms)', alpha=0.8)
            delay_plotted = True
            print(f"Found {valid_send_mask.sum()} valid send_delay values")
    
    if 'ack_delay_ms' in bbr_df_plot.columns:
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ack_delayæ•°æ®
        valid_ack_mask = (~bbr_df_plot['ack_delay_ms'].isnull()) & (bbr_df_plot['ack_delay_ms'] > 0) & (bbr_df_plot['ack_delay_ms'] < 10000)
        if valid_ack_mask.any():
            ax6.plot(bbr_df_plot['time_sec'], bbr_df_plot['ack_delay_ms'], 'orange', linewidth=1.5, 
                    label='Ack Delay (ms)', alpha=0.8, linestyle='--')
            delay_plotted = True
            print(f"Found {valid_ack_mask.sum()} valid ack_delay values")
    
    # æ·»åŠ çŠ¶æ€è½¬æ¢å‚ç›´çº¿
    if 'bbr_state' in bbr_df_plot.columns:
        state_changes = bbr_df_plot[bbr_df_plot['bbr_state'] != bbr_df_plot['bbr_state'].shift(1)]
        for _, row in state_changes.iterrows():
            ax6.axvline(x=row['time_sec'], color='darkgoldenrod', linestyle='--', alpha=0.6, linewidth=1.0)
            ax6.text(row['time_sec'], ax6.get_ylim()[1]*0.9, row['bbr_state'], 
                    rotation=90, ha='right', va='top', fontsize=8,
                    bbox=dict(facecolor='white', alpha=0.8))
    
    # å¦‚æœæœ‰å»¶è¿Ÿæ•°æ®ï¼Œæ·»åŠ ç»Ÿè®¡ä¿¡æ¯ - ä½¿ç”¨valid_df
    if delay_plotted:
        stats_text = ""
        if 'send_delay_ms' in valid_df.columns and not valid_df['send_delay_ms'].isnull().all():
            avg_send_delay = valid_df['send_delay_ms'].mean()
            max_send_delay = valid_df['send_delay_ms'].max()
            median_send_delay = valid_df['send_delay_ms'].median()
            stats_text += f"Send Delay (ms):\n  Avg: {avg_send_delay:.2f}\n  Max: {max_send_delay:.2f}\n  Median: {median_send_delay:.2f}\n\n"
        
        if 'ack_delay_ms' in valid_df.columns and not valid_df['ack_delay_ms'].isnull().all():
            avg_ack_delay = valid_df['ack_delay_ms'].mean()
            max_ack_delay = valid_df['ack_delay_ms'].max()
            median_ack_delay = valid_df['ack_delay_ms'].median()
            stats_text += f"Ack Delay (ms):\n  Avg: {avg_ack_delay:.2f}\n  Max: {max_ack_delay:.2f}\n  Median: {median_ack_delay:.2f}"
        
        if stats_text:
            ax6.text(0.02, 0.98, stats_text, transform=ax6.transAxes, 
                    verticalalignment='top', bbox=dict(facecolor='white', alpha=0.8))
        
        ax6.legend(loc='upper right')
    else:
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        send_delay_info = "No send_delay_ms column"
        ack_delay_info = "No ack_delay_ms column"
        
        if 'send_delay_ms' in bbr_df_plot.columns:
            send_delay_count = (~bbr_df_plot['send_delay_ms'].isnull()).sum()
            send_delay_info = f"send_delay_ms: {send_delay_count} non-null values"
            if send_delay_count > 0:
                sample_values = bbr_df_plot['send_delay_ms'].dropna().head(5).tolist()
                send_delay_info += f", samples: {[f'{v:.2f}' for v in sample_values]}"
        
        if 'ack_delay_ms' in bbr_df_plot.columns:
            ack_delay_count = (~bbr_df_plot['ack_delay_ms'].isnull()).sum()
            ack_delay_info = f"ack_delay_ms: {ack_delay_count} non-null values"
            if ack_delay_count > 0:
                sample_values = bbr_df_plot['ack_delay_ms'].dropna().head(5).tolist()
                ack_delay_info += f", samples: {[f'{v:.2f}' for v in sample_values]}"
        
        ax6.text(0.5, 0.5, f'No valid delay data available\n{send_delay_info}\n{ack_delay_info}', 
                transform=ax6.transAxes, ha='center', va='center', fontsize=10,
                bbox=dict(facecolor='white', alpha=0.8))
    
    ax6.set_ylabel('Delay (ms)')
    ax6.set_title('BBR Send and Ack Delays (for Delivery Rate Calculation)', **title_style)
    ax6.grid(True, alpha=0.3)
    
    # å›¾7: åˆå¹¶åçš„ä¸¢åŒ…åˆ†æå›¾ - æ˜¾ç¤ºä¸¢åŒ…äº‹ä»¶æ•°é‡å’Œä¸¢åŒ…æ€»æ•°
    ax7 = axes[current_ax_idx]
    current_ax_idx += 1
    
    if retransmission_df is not None and not retransmission_df.empty:
        # ä½¿ç”¨æŸ±çŠ¶å›¾ä»£æ›¿æ•£ç‚¹å›¾æ¥æ˜¾ç¤ºä¸¢åŒ…äº‹ä»¶
        # åˆ›å»ºæ—¶é—´æ¡¶ï¼ˆbinsï¼‰- æ ¹æ®æ€»æ—¶é•¿è®¾ç½®åˆç†çš„æ¡¶å¤§å°
        total_duration = retransmission_df['time_sec'].max() - retransmission_df['time_sec'].min()
        
        # åŠ¨æ€è°ƒæ•´binå¤§å°
        if total_duration <= 1.0:
            bin_size = 0.01  # 10ms
        elif total_duration <= 5.0:
            bin_size = 0.05  # 50ms
        elif total_duration <= 10.0:
            bin_size = 0.1   # 100ms
        elif total_duration <= 60.0:
            bin_size = 0.5   # 500ms
        else:
            bin_size = 1.0   # 1s
        
        # åˆ›å»ºæ—¶é—´æ¡¶
        min_time = retransmission_df['time_sec'].min()
        max_time = retransmission_df['time_sec'].max()
        
        # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªbin
        if max_time == min_time:
            max_time = min_time + bin_size
        
        # ç¡®ä¿æ—¶é—´èŒƒå›´ä¸æ€»æ—¥å¿—æ•°æ®ä¸€è‡´ï¼Œä»¥ä¾¿ä¸å…¶ä»–å›¾è¡¨å¯¹é½
        if bbr_df is not None and not bbr_df.empty:
            global_min_time = bbr_df['time_sec'].min()
            global_max_time = bbr_df['time_sec'].max()
            
            if global_min_time < min_time:
                min_time = global_min_time
            
            if global_max_time > max_time:
                max_time = global_max_time
            
        bins = np.arange(min_time, max_time + bin_size, bin_size)
        
        # è®¡ç®—binä¸­å¿ƒç‚¹ä½ç½®ï¼ˆç”¨äºç»˜å›¾ï¼‰
        bin_centers = (bins[:-1] + bins[1:]) / 2
        
        # åˆ›å»ºä¸€ä¸ªæ–°çš„DataFrameï¼ŒæŒ‰æ—¶é—´binåˆ†ç»„å¹¶èšåˆä¸¢åŒ…æ•°æ®
        bin_indices = np.digitize(retransmission_df['time_sec'], bins) - 1
        
        # ç¡®ä¿ç´¢å¼•åœ¨æœ‰æ•ˆèŒƒå›´å†…
        bin_indices = np.clip(bin_indices, 0, len(bins)-2)
        
        # åˆ›å»ºåŒ…å«binç´¢å¼•å’Œä¸¢åŒ…æ•°çš„DataFrame
        binned_data = pd.DataFrame({
            'bin_idx': bin_indices,
            'lost_packets': retransmission_df['lost_packets']
        })
        
        # Group by bin and aggregate lost packets
        agg_data = binned_data.groupby('bin_idx').agg({
            'lost_packets': 'sum',  # Calculate total lost packets in each bin
        }).reset_index()
        
        # è®¡ç®—æ¯ä¸ªbinä¸­çš„äº‹ä»¶æ•°é‡
        event_counts = binned_data.groupby('bin_idx').size().reset_index(name='event_count')
        
        # åˆå¹¶ä¸¢åŒ…æ•°å’Œäº‹ä»¶æ•°
        agg_data = pd.merge(agg_data, event_counts, on='bin_idx', how='left')
        
        # åˆ›å»ºå®Œæ•´çš„binæ•°ç»„ï¼ˆåŒ…æ‹¬æ²¡æœ‰ä¸¢åŒ…çš„binï¼‰
        full_bin_data = pd.DataFrame({
            'bin_idx': range(len(bins) - 1),
            'bin_center': bin_centers
        })
        
        # åˆå¹¶æ•°æ®
        merged_data = full_bin_data.merge(agg_data, on='bin_idx', how='left').fillna(0)
        
        # åˆ›å»ºåŒYè½´å›¾è¡¨
        ax7b = ax7.twinx()
        
        # ç»˜åˆ¶æŸ±çŠ¶å›¾ - æ˜¾ç¤ºæ¯ä¸ªæ—¶é—´æ®µå†…çš„äº‹ä»¶æ•°é‡
        bar_container = ax7.bar(merged_data['bin_center'], merged_data['event_count'], 
               width=bin_size*0.8, alpha=0.6, color='blue', edgecolor='darkblue', 
               label='Loss Events Count')
        
        # ä½¿ç”¨æŠ˜çº¿å›¾æ˜¾ç¤ºæ¯ä¸ªæ—¶é—´æ®µå†…çš„æ€»ä¸¢åŒ…æ•°ï¼Œåªåœ¨æœ‰ä¸¢åŒ…çš„ç‚¹æ˜¾ç¤ºæ ‡è®°
        # å…ˆç”»çº¿
        line = ax7b.plot(merged_data['bin_center'], merged_data['lost_packets'], 'r-', 
                       linewidth=1.5, label='Total Packets Lost', alpha=0.8)
        
        # åªåœ¨æœ‰ä¸¢åŒ…çš„ç‚¹ä¸Šæ·»åŠ æ ‡è®°
        nonzero_loss = merged_data[merged_data['lost_packets'] > 0]
        if not nonzero_loss.empty:
            ax7b.scatter(nonzero_loss['bin_center'], nonzero_loss['lost_packets'],
                      color='r', s=25, zorder=5, label='_nolegend_')
        
        # æ·»åŠ å•ä¸ªäº‹ä»¶çš„ä¸¢åŒ…æƒ…å†µï¼ˆä½¿ç”¨èŒçŠ¶å›¾ï¼‰
        if len(retransmission_df) < 100:  # ä»…åœ¨äº‹ä»¶è¾ƒå°‘æ—¶æ˜¾ç¤ºå•ä¸ªäº‹ä»¶è¯¦æƒ…
            markerline, stemlines, baseline = ax7b.stem(retransmission_df['time_sec'], 
                                                      retransmission_df['lost_packets'],
                                                      linefmt='r--', markerfmt='.', basefmt=' ',
                                                      label='Individual Loss Events')
            plt.setp(markerline, markersize=3, alpha=0.6)
            plt.setp(stemlines, linewidth=0.8, alpha=0.4)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        total_loss_events = len(retransmission_df)
        total_lost_packets = retransmission_df['lost_packets'].sum()
        total_duration = max_time - min_time if max_time > min_time else bin_size
        avg_loss_events_per_sec = total_loss_events / total_duration if total_duration > 0 else 0
        avg_packets_lost_per_sec = total_lost_packets / total_duration if total_duration > 0 else 0
        
        stats_text = f"Total Loss Events: {total_loss_events}\n"
        stats_text += f"Total Packets Lost: {int(total_lost_packets)}\n"
        stats_text += f"Avg Events Rate: {avg_loss_events_per_sec:.2f} events/sec\n"
        stats_text += f"Avg Loss Rate: {avg_packets_lost_per_sec:.2f} pkts/sec"
        
        if 'persistent_congestion' in retransmission_df.columns:
            persistent_count = retransmission_df['persistent_congestion'].sum()
            if persistent_count > 0:
                stats_text += f"\nPersistent Congestion Events: {persistent_count}"
        
        # è®¡ç®—ä¸¢åŒ…ç‡ï¼ˆåŸºäºäº‹ä»¶ï¼‰
        if 'total_sent' in retransmission_df.columns and 'total_lost' in retransmission_df.columns:
            if len(retransmission_df) > 0:
                last_record = retransmission_df.iloc[-1]
                if last_record['total_sent'] > 0:
                    total_loss_rate = (last_record['total_lost'] / last_record['total_sent']) * 100
                    stats_text += f"\nOverall Loss Rate: {total_loss_rate:.3f}%"
        
        ax7.text(0.02, 0.98, stats_text, transform=ax7.transAxes, 
                verticalalignment='top', bbox=dict(facecolor='white', alpha=0.8))
        
        # è®¾ç½®Yè½´æ ‡ç­¾ï¼Œä½¿ç”¨ä¸å…¶ä»–å›¾è¡¨ä¸€è‡´çš„é¢œè‰²
        ax7.set_ylabel('Loss Events Count')
        
        ax7b.set_ylabel('Packets Lost')
        
        # åˆå¹¶ä¸¤ä¸ªå›¾ä¾‹
        lines1, labels1 = ax7.get_legend_handles_labels()
        lines2, labels2 = ax7b.get_legend_handles_labels()
        ax7.legend(lines1 + lines2, labels1 + labels2, loc='upper right')
        
        # æ˜ç¡®è®¾ç½®Xè½´æ—¶é—´åˆ»åº¦
        # æ ¹æ®æ€»æ—¶é•¿åŠ¨æ€è®¾ç½®ä¸»åˆ»åº¦å’Œæ¬¡åˆ»åº¦
        if total_duration <= 1.0:
            ax7.xaxis.set_major_locator(MultipleLocator(0.2))
            ax7.xaxis.set_minor_locator(MultipleLocator(0.05))
        elif total_duration <= 5.0:
            ax7.xaxis.set_major_locator(MultipleLocator(1.0))
            ax7.xaxis.set_minor_locator(MultipleLocator(0.2))
        elif total_duration <= 10.0:
            ax7.xaxis.set_major_locator(MultipleLocator(5.0))
            ax7.xaxis.set_minor_locator(MultipleLocator(1.0))
        elif total_duration <= 60.0:
            ax7.xaxis.set_major_locator(MultipleLocator(10.0))
            ax7.xaxis.set_minor_locator(MultipleLocator(2.0))
        else:
            ax7.xaxis.set_major_locator(MultipleLocator(30.0))
            ax7.xaxis.set_minor_locator(MultipleLocator(10.0))
        
        # è®¾ç½®ç½‘æ ¼çº¿
        ax7.grid(True, which='major', axis='both', linestyle='-', alpha=0.5)
        ax7.grid(True, which='minor', axis='x', linestyle=':', alpha=0.2)
        
        # æ‰¾å‡ºæŒç»­æ‹¥å¡äº‹ä»¶å¹¶åœ¨å›¾ä¸Šæ ‡è®°
        if 'persistent_congestion' in retransmission_df.columns:
            persistent_events = retransmission_df[retransmission_df['persistent_congestion'] == True]
            if len(persistent_events) > 0:
                for _, row in persistent_events.iterrows():
                    ax7.axvline(x=row['time_sec'], color='darkred', linestyle='-', alpha=0.6, linewidth=1.5)
                    ax7.text(row['time_sec'], ax7.get_ylim()[1]*0.95, "PersistentCongestion", 
                            rotation=90, ha='right', va='top', fontsize=8, color='darkred',
                            bbox=dict(facecolor='white', alpha=0.8))
        
    else:
        ax7.text(0.5, 0.5, 'No packet loss events data available', 
                transform=ax7.transAxes, ha='center', va='center', fontsize=12,
                bbox=dict(facecolor='white', alpha=0.8))
    
    ax7.set_title('Packet Loss Analysis: Events Count and Total Lost Packets', **title_style)
    
    # ç¡®ä¿æœ€åä¸€ä¸ªå›¾çš„Xè½´æ ‡ç­¾æ˜¾ç¤º
    ax7.set_xlabel('Time (seconds)')
    
    # ä¸ºæ‰€æœ‰å­å›¾è®¾ç½®ç»Ÿä¸€çš„Xè½´æ ¼å¼
    for ax_idx in range(current_ax_idx):
        ax = axes[ax_idx]
        if bbr_df_plot is not None and not bbr_df_plot.empty:
            total_duration = bbr_df_plot['time_sec'].max() - bbr_df_plot['time_sec'].min()
            
            # æ ¹æ®æ€»æ—¶é•¿åŠ¨æ€è®¾ç½®ä¸»åˆ»åº¦å’Œæ¬¡åˆ»åº¦
            if total_duration <= 1.0:
                ax.xaxis.set_major_locator(MultipleLocator(0.2))
                ax.xaxis.set_minor_locator(MultipleLocator(0.05))
            elif total_duration <= 5.0:
                ax.xaxis.set_major_locator(MultipleLocator(1.0))
                ax.xaxis.set_minor_locator(MultipleLocator(0.2))
            elif total_duration <= 30.0:
                ax.xaxis.set_major_locator(MultipleLocator(5.0))
                ax.xaxis.set_minor_locator(MultipleLocator(1.0))
            elif total_duration <= 60.0:
                ax.xaxis.set_major_locator(MultipleLocator(10.0))
                ax.xaxis.set_minor_locator(MultipleLocator(2.0))
            elif total_duration <= 600.0:
                ax.xaxis.set_major_locator(MultipleLocator(60.0))
                ax.xaxis.set_minor_locator(MultipleLocator(15.0))
            else:
                ax.xaxis.set_major_locator(MultipleLocator(120.0))
                ax.xaxis.set_minor_locator(MultipleLocator(30.0))
            
            # è®¾ç½®ç½‘æ ¼çº¿
            ax.grid(True, which='major', axis='x', linestyle='-', alpha=0.5)
            ax.grid(True, which='minor', axis='x', linestyle=':', alpha=0.2)
            ax.grid(True, which='major', axis='y', alpha=0.3)
    
    # åªåœ¨æœ€åº•éƒ¨çš„å­å›¾æ˜¾ç¤ºxè½´æ ‡ç­¾
    for ax_idx in range(current_ax_idx - 1):
        axes[ax_idx].set_xlabel('')
        # ä¿ç•™åˆ»åº¦ä½†éšè—åˆ»åº¦æ ‡ç­¾ï¼ˆå¯é€‰ï¼‰
        # axes[ax_idx].tick_params(axis='x', which='both', labelbottom=False)
    
    # æœ€åä¸€ä¸ªå­å›¾æ˜¾ç¤ºxè½´æ ‡ç­¾
    axes[current_ax_idx - 1].set_xlabel('Time (seconds)')
    
    # æ·»åŠ æ•°æ®ä¿¡æ¯åˆ°å›¾è¡¨æ ‡é¢˜
    if not aggregated and original_length != len(bbr_df_plot):
        fig.suptitle(f'BBR Analysis - All Original Data Points (Showing {len(bbr_df_plot):,} of {original_length:,} points)', 
                    fontsize=16, fontweight='bold', y=0.98)
    elif not aggregated:
        fig.suptitle(f'BBR Analysis - All Original Data Points ({len(bbr_df_plot):,} points)', 
                    fontsize=16, fontweight='bold', y=0.98)
    else:
        fig.suptitle(f'BBR Analysis - Aggregated Data ({len(bbr_df_plot):,} points)', 
                    fontsize=16, fontweight='bold', y=0.98)
    
    plt.tight_layout()
    plt.subplots_adjust(top=0.93)
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"Charts saved to {output_file}")

def main():
    parser = argparse.ArgumentParser(description="BBR 4-Chart Analyzer")
    parser.add_argument("log_file", help="Path to the log file")
    parser.add_argument("--output", help="Output image path")
    parser.add_argument("--max-lines", type=int, help="Maximum lines to process")
    parser.add_argument("--time-window", type=float, default=0.1, help="Time window for data aggregation in seconds (default: 0.1)")
    parser.add_argument("--aggregate", action="store_true", help="Aggregate data points by time window")
    parser.add_argument("--rtt-style", choices=['scatter', 'line', 'density', 'percentiles'], 
                       default='scatter', help="RTT visualization style (default: scatter)")
    args = parser.parse_args()
    
    # ç¡®å®šè¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_file = args.output
    if not output_file:
        basename = os.path.basename(args.log_file).split('.')[0]
        suffix = "_aggregated" if args.aggregate else "_all_points"
        output_file = f"{basename}_bbr_4charts{suffix}.png"
    
    # åˆ†ææ—¥å¿— - é»˜è®¤ä½¿ç”¨æ‰€æœ‰æ•°æ®ç‚¹ï¼Œé™¤éæŒ‡å®š--aggregate
    aggregate_data = args.aggregate
    bbr_df, delivery_rate_df, retransmission_df = analyze_log(args.log_file, args.max_lines, args.time_window, aggregate_data)
    
    if bbr_df is None:
        print("No BBR data found in log file.")
        return
    
    # ç»˜åˆ¶BBRåˆ†æå›¾è¡¨ï¼ˆåŒ…å«å»¶è¿Ÿåˆ†æï¼‰
    plot_four_charts(bbr_df, delivery_rate_df, retransmission_df, output_file, aggregate_data, args.rtt_style)
    
    # æ‰“å°åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š Analysis Summary:")
    print(f"   Total BBR entries: {len(bbr_df)}")
    print(f"   Duration: {bbr_df['time_sec'].max():.2f} seconds")
    
    if 'bbr_state' in bbr_df.columns:
        state_counts = bbr_df['bbr_state'].value_counts()
        print(f"   BBR State Distribution:")
        for state, count in state_counts.items():
            percentage = (count / len(bbr_df)) * 100
            print(f"     {state}: {count} ({percentage:.1f}%)")
    
    if retransmission_df is not None and not retransmission_df.empty:
        print(f"   Total packet losses: {len(retransmission_df)}")
    else:
        print(f"   No packet loss events detected")

if __name__ == "__main__":
    plt.switch_backend('agg')
    main() 